12    Validation and review

Validation is the automatic software routine to check that data are valid according to the internal rules set for the ecoinvent database.
Review is the manual inspection of the data and commenting on any discovered errors or anomalous data that require additional explanation or justification.

12.1   Validation
The automatic validation of ecoinvent data covers the
     accordance with the ecoSpold 2 data format,
     accordance with additional ecoinvent-specific rules, as described in this document,
    plausibility of the data,
and takes place in several steps:
The ecoEditor software, used by data providers to create and edit data for the ecoinvent database, se- cures the validity of the data against the ecoSpold 2 data format already during editing. Likewise, some validations of accordance with ecoinvent-specific rules can also be performed directly upon data entry, e.g. “Time period shall be minimum one year” .
Other validation checks can be made off-line (i.e. without contact to the ecoinvent database) in the ecoEditor software, upon user request, typically before storing an edited dataset, e.g. “An ISIC class must be chosen”, and “More than one reference product in the same activity dataset” . The latter is an example of a validation check that does not lead to a rejection of the dataset (i.e. it can still be submit- ted to the database for review), but results in a warning to the user (here that “'It is unusual to have more than one reference product. This occurs only when no alternative production routes exist for these products. If you are in doubt which of the products is the reference product or if you think there
should indeed be more than one reference product for this activity, please consult the ecoinvent Data
Quality Guideline Chapter11.1for further advice.”).
Other validation checks require contact to the production version of the ecoinvent database, because they require a check against data that already exist in the database, e.g., “Global dataset must exist be- fore non-global datasets can be uploaded”, and “Production volume of datasets for a specific activity, time period and macro-economic scenario must not exceed production volume of the corresponding
global dataset” . Such validation checks also apply for deletion of datasets, e.g. “A parent dataset can-
not be deleted” (deletion of datasets can only be done by the ecoinvent editors, see Chapter 12.2, but can be suggested on the relevant discussion boards on the Editor's pages, see Chapter16.4.)
Validation checks that require contact to the database can either be performed via the ecoEditor soft- ware when this is in on-line contact with the database, [Feature considered for implementation lat- er: or by submitting the dataset to the ecoinvent database for validation via a web-browser]. When us- ing the ecoEditor on-line, the validation result will be inserted directly in the dataset (in the ecoSpold field 3340 Validation details). Only the latest validation result will be stored (i.e. any previous valida- tion results will be over-written). If submitting a dataset via a web-browser, the validation result (a text message) will be returned by e-mail.
The plausibility checks generally do not lead to rejection of a dataset (i.e. it can still be submitted to the database for review), but results in a requirement to justify the anomalous value in the adjoining comment field, if the anomalous value is maintained. An implausible entry without an adequate justi- fication will be returned by the reviewer.



Plausibility checks generally compare the data entries to similar entries in similar datasets. Thereby, the completeness of the data is checked (missing exchanges or missing entries in fields where all simi- lar datasets have entries); it is checked that the entries fall within expected ranges (relative to the amount of the reference product or relative to well-established relations between different amounts and/or properties of specified exchanges). Results of mass and monetary balances are also reported in the validation results.
The plausibility checks obviously relate to the existing database, specific clusters of similar datasets within the database, and knowledge about what are typical and important errors and relationships be- tween individual data values within each cluster. This knowledge is built up over time, and is based on a continuous learning cycle of learning from past errors, software-supported explorative data anal- ysis, interaction with expert knowledge, and cluster analysis. Thus, the plausibility checks will im- prove over time, and will be implemented in the ecoEditor and the database software, as part of the continuous maintenance and updating. [At the time of the release of version 3.0: Plausibility checks are largely missing]
[Changes relative to ecoinvent version 2: Validation is more extensive.]

12.2    Review of dataset and documentation
All transforming activity datasets are reviewed by at least three experts prior to the storage of the da- tasets in the database. [At the time of the release of version 3.0: Not all datasets have so far been re- viewed by at least three experts. Such datasets are to be submitted to a more extensive review at a lat- er date.]

12.2.1  Types of editors
There are three overall types of ecoinvent editors: activity editors, cross-cutting editors, and LCIA ed- itors. Cross-cutting editors can further be sub-divided in geographical editors, inventory indicator edi- tors, meta-data editors and language editors. Each of these types of editors will be described in the following:
Activity editors: Activity editors are responsible for reviewing of data for a specific industry, technol- ogy or other human activity. The activity editor is the main reviewer for a dataset; she/he is the first to receive a submitted dataset, and the last to accept it for final upload to the current beta-version of the database. Activity editors are typically leading (LCA) experts within their activity area. The activity editors divide the work between them according to the ISIC (Rev. 4, ecoinvent-amended) codes of the datasets and/or the type of dataset. The main editor may re-assign a dataset to a co-editor with special expertise but still request to remain as main editor for the dataset . In this case, the dataset will first be reviewed by the co-editor and then by the main editor for overall consistency. An activity editor is in principle responsible for all datasets within an activity area, disregarding any geographical differences (exactly to ensure global consistency of activity datasets, i.e. across all geographies). When a dataset has been reviewed by the activity editor, it is passed on to the cross-cutting editors:
Geographical editors: A geographical editor is responsible for datasets that fall geographically within a specific country or other geographical area, ensuring that geographical variation in technologies are correctly and consistently captured and integrated across all datasets for that area. If the ecoinvent Centre cooperates with a national data collection initiative in a country, the geographical editor for that country will typically be appointed after suggestion by the national data collection initiative.



Inventory indicator editors: An inventory indicator editor is responsible for a specific emission (or group  of emissions),  e.g. particle  emissions,  or  other  environmental pressure  indicators  (e.g. re- sources, land use, noise, social aspects)8, ensuring the consistency across all datasets.                            Meta-data editors: A meta-data editor is responsible for ensuring the consistent use across all datasets of a specific database field (or group of fields) or master file entries, e.g. for name fields, statistical classifications, free documentation fields, supply-use data, geography fields, system models, scenari- os, uncertainty fields, and product properties. Meta-data editors for required product properties, such as mass, carbon content and price, have the additional task to suggest data when these are not supplied by the data provider.
Language editors: A language editor is responsible for checking consistency and quality of transla- tions within a specific language version of the ecoinvent datasets, and may maintain a vocabulary for automatic pre-translations. Language editors will only receive datasets for review when they contain translated fields in their specific language.
LCIA editors: LCIA editors are responsible for impact assessment datasets, not activity datasets. In this way, they work in parallel to the activity editors. There are two kinds of LCIA editors: LCIA method editors and LCIA pathway editors. An LCIA method editor is responsible for the maintenance of the ecoinvent version of a specific LCIA method (CML, Ecoindicator, etc.). The LCIA method edi- tors are both responsible for the correctness of the mapping of the environmental pressure indicators (“Elementary exchanges”) between the ecoinvent inventories and the specific LCIA method, and for the correspondence of the numerical entries in the ecoinvent implementation with those of the original published method. An LCIA pathway editor is responsible for the consistency of the implementation of a specific impact category and/or pathway (for noise, water resources, etc.) across all relevant LCIA methods. LCIA editors are involved both when an LCIA method is updated by the method de- veloper, and when new environmental pressure indicators are added to the ecoinvent database. The only cross-cutting editors which are relevant for impact assessment datasets are the language editors. Thus, when an impact assessment dataset has been reviewed by the LCIA editor(s), and it contains translated fields, it is passed on to the language editor.

12.2.2  The flow of a dataset through the editorial process
When a data provider submits the dataset via the ecoEditor software [Feature considered for im- plementation later: or via the ecoinvent web-site], the software stores it and assigns it to the relevant editor. For a transforming activity dataset this will be determined by the statistical classification as- signed to the dataset by the data provider. For production and supply mixes and market activity da- tasets this is the editor for wholesale and retail trade. For import datasets and supply-use data, this is the meta-editor for supply-use data. For an LCIA method dataset this will be determined by the name of the method or impact category.
The original data provider (author) of a dataset can ask to be ‘active author’ and will then be informed whenever there are other data providers that suggest modifying the dataset in question and can decide to take over the suggestion (and thus remain as author of the dataset) or comment on the suggested modifications before the dataset is passed on to the activity or LCIA editor.
If the dataset is an edited version of an existing parent dataset, the consequences for the child datasets are reviewed at the same time as the edited parent dataset.
The main editor may pass on the dataset and review responsibility to a co-editor if temporarily una- vailable due to workload, holidays or illness, or ifjudging that the co-editor has more scientific exper-


8  Environmental pressure indicators are called ”Elementary Flows” in the ISO 14040 series, and “elementary exchanges” or “exchanges with the environment” in ecoinvent.



tise for the particular dataset in question. When passing on a dataset to a co-editor, the original re- sponsible editor indicates whether the co-editor thereby becomes the responsible editor for this da- taset or whether the original main editor remains as responsible editor, in which case the dataset will first be reviewed by the co-editor and then by the main editor for overall consistency. In case of con- flicts of interests, any editor is required to pass on the dataset and review responsibility to a co-editor, and shall not demand to remain as responsible editor.
Having accepted the dataset for review, the responsible editor adds any review comments to the file. If a dataset is a delta/child dataset or a new version of an existing dataset, only those parts of the dataset are reviewed that are different from the parent or are affected by the changes. The purpose of the re- view is to check the dataset against the data quality guidelines in this document, to check that the re- sult of the automatic validation has been adequately addressed, and to check the plausibility of the da- taset against the “real life” activity that it is intended to represent. As part of the review, the editor may also compare the new dataset with an older version or a similar dataset. For delta/child datasets, the editor also considers whether entries correctly belong in the delta dataset, or should rather have been placed in the parent dataset.
If the review comments are of a nature that revision by the data provider is required, the commented dataset is returned to the data provider for re-submission. This procedure may continue until the re- sponsible editor is satisfied with the quality of the submitted dataset.
When the responsible editor has accepted the dataset, the data provider is informed and the dataset now passes on to the cross-cutting editors. Depending on its content, the dataset can be passed on in parallel to several cross-cutting editors:
All activity datasets except global datasets are passed on to the relevant geographical editor.
Inventory indicator editors receive activity datasets if they contain data on their specifically monitored environmental pressure indicators (elementary exchanges). If the dataset is a new version of an exist- ing dataset, it is only passed on if there are changes for the monitored indicators. More than one in- ventory indicator editor may be involved in the review of the same activity dataset.
Meta-data editors receive activity datasets if they contain information in one of the fields specifically monitored by them. If the dataset is a new version of an existing dataset, it is only passed on if there are changes for the monitored fields. More than one meta-data editor may be involved in the review of the same activity dataset.
Language editors receive datasets if they contain translated fields in their specific language. Datasets that have multiple languages may thus be passed on to several language editors in parallel. If the da- taset is a new version of an existing dataset, it is only passed on if there are changes for the text or name fields, or when a new language has been added.
If responses are given by one or more cross-cutting editor, these responses are automatically accumu- lated into one review version, which is passed on to the data provider for corrections and resubmis- sion. The resubmitted dataset is returned to the editors which have given comments. This procedure may continue until the cross-cutting editors are satisfied with the quality of the submitted dataset.
When the dataset has successfully passed the cross-cutting review, the data provider is informed and the dataset passes back to the responsible editor. If there has been changes made during the cross- cutting review, the responsible editor performs a final review. After this final review, the responsible editor uploads the dataset to the current production version of the database, and the data provider is informed.
Editors seek to process submitted datasets within 14 days of receipt, but may request a prolongation of the review period during peak load, in which case the data provider will be informed. The mini- mum time between submission of a dataset and its inclusion in the production database is one month, but will usually require more time due to several rounds of comments and replies between editors and data providers.



The review procedure is comparable to the critical panel review specified in the ISO standards.
It has to be emphasised that the responsibility for the contents of all datasets remains with the person and institute who supplies the data. The reviewer helps to improve the quality of datasets with his or her suggestions. But it is the final decision of the dataset author whether all proposals for corrections of the data are implemented, just as it is the decision of the activity editor whether a dataset can be in- cluded in the database or not. If an editor repeatedly returns a dataset, and this is regarded by the au- thor as unfounded, the author may address a complaint to the ecoinvent LCI Expert Group that has the final decision authority on scientific matters raised by the Editorial Board or arising from complaints.
[Changes relative to ecoinvent version 2: Review is more extensive and now performed by domain experts.]

12.3    “Fast track” review for smaller changes
Outlook: For adding tags to a dataset and for smaller corrections to a dataset (e.g. correcting spelling errors, adding, editing or deleting single entries that are obviously wrong), which do not require a full review  of  the  entire  dataset,  a  “fast  track”  submission  procedure  via  the  ecoinvent  web-site <www.ecoinvent.org> is considered. This will avoid the need to download and install the ecoEditor software if it is only single entries that are to be submitted for review. The review procedure for such submissions will also be streamlined, to limit the workload on the editors, and to reduce the time be- tween submission and publication.

12.4    Confidentiality
Confidentiality concerns of a data provider and requests for confidentiality agreements should nor- mally be referred to the ecoinvent database administrator. When the data provider has set the ac- cessRestrictedTo to either “2 = ResultsOnly” or “3 = Restricted” , the dataset will not even arrive at the editor’s desk, but will be redirected to and handled by the ecoinvent administrator directly. Confi- dential datasets are subject to the same data quality guidelines as any other ecoinvent dataset, but the review procedure will be performed under the direct management of the ecoinvent administrator that signs and/or manages the necessary confidentiality agreements, also in case of re-delegation of the re- view to independent reviewers.
The ecoinvent Centre accepts no responsibility for confidentiality agreements made directly between editors and a data provider.

12.5    On-site auditing
Branded datasets require on-site review by an ecoinvent-approved auditor. A visit to the factory and auditing of the books is required to determine that the activity is correctly and completely represented in the dataset. Audits are performed according to ISO 19011 and with Weidema et al. (2003) as tech- nical basis. On-site audits may require the signing of a confidentiality agreement, and is always organ- ised with the assistance of the ecoinvent administration.
